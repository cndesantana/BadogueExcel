theme(axis.text.x = element_text(angle = 90, hjust = 1)) +
ylab("Numero de ocorrencias") +
xlab("Palavras") + coord_flip()
print(p);
words_td
words_td %>%
count(sentimento, term, n = count) %>%
ungroup() %>%
filter(n >= 3) %>%
mutate(term = reorder(term, n))
words_td %>%
count(sentimento, term, n = count) %>%
ungroup() %>%
filter(n >= 3)
words_td %>%
count(sentimento, term, n = count) %>%
ungroup() %>%
filter(n > 3)
words_td %>%
count(sentimento, term, n = count) %>%
ungroup() %>%
filter(n > 5)
p <-
%>%
mutate(term = reorder(term, n)) %>%
ggplot(aes(term, n, fill = sentimento)) +
geom_bar(stat="identity", fill="magenta") +
theme(axis.text.x = element_text(angle = 90, hjust = 1)) +
ylab("Numero de ocorrencias") +
xlab("Palavras") + coord_flip()
words_td %>%
count(sentimento, term, wt = count) %>%
ungroup() %>%
filter(n >= 5) %>%
mutate(term = reorder(term, n)) %>%
ggplot(aes(term, n, fill = sentimento)) +
geom_bar(stat="identity", fill="magenta") +
theme(axis.text.x = element_text(angle = 90, hjust = 1)) +
ylab("Numero de ocorrencias") +
xlab("Palavras") + coord_flip()
words_td %>%
count(sentimento, term, wt = count) %>%
ungroup() %>%
filter(n >= 3) %>%
mutate(term = reorder(term, n)) %>%
ggplot(aes(term, n, fill = sentimento)) +
geom_bar(stat="identity", fill="magenta") +
theme(axis.text.x = element_text(angle = 90, hjust = 1)) +
ylab("Numero de ocorrencias") +
xlab("Palavras") + coord_flip()
getTidyWords <- function(text){
myCorpus <- corpus(text)
metadoc(myCorpus, "language") <- "portuguese"
tokenInfo <- summary(myCorpus)
kwic(myCorpus, "gestor")
myStemMat <- dfm(myCorpus, remove = stopwords("portuguese"), stem = TRUE, remove_punct = TRUE)
mydfm <- dfm(myCorpus, remove = c(stopwords("portuguese"),"scontent.xx.fbcdn.net","https","oh","oe","pra"," v ","como","para","de","do","da","das","dos","isso","esse","nisso","nesse","aquele","nesses","aqueles","aquela","aquelas","que","q","é","sr"), remove_punct = TRUE, remove_numbers= TRUE)
ap_td <- tidy(mydfm)
names(ap_td) <- c("sentimento","term","count")
return(ap_td);
}
words_td <- getTidyWords(text);
p <- words_td %>%
count(sentimento, term, wt = count) %>%
ungroup() %>%
filter(n >= 3) %>%
mutate(term = reorder(term, n)) %>%
ggplot(aes(term, n, fill = sentimento)) +
geom_bar(stat="identity", fill="magenta") +
theme(axis.text.x = element_text(angle = 90, hjust = 1)) +
ylab("Numero de ocorrencias") +
xlab("Palavras") + coord_flip()
print(p);
write.csv(words_td)
write.csv(words_td,file="palavrasrui.csv")
getwd()
words_td %>%
count(sentimento, term, wt = count) %>%
ungroup() %>%
filter(wt >= 3) %>%
mutate(term = reorder(term, wt))
words_td %>%
count(sentimento, term, wt = count) %>%
ungroup() %>%
filter(n >= 3)
words_td %>%
count(sentimento, term, wt = count) %>%
ungroup() %>%
filter(n >= 3) %>%
select(sentimento,term,wt)
words_td %>%
count(sentimento, term, wt = count) %>%
ungroup() %>%
filter(n >= 3) %>%
mutate(term = reorder(term, wt))
words_td %>%
count(sentimento, term, wt = count) %>%
ungroup() %>%
filter(n >= 3)
words_td %>%
count(sentimento, term, wt = count) %>%
ungroup() %>%
filter(n >= 3) %>%
mutate(term = reorder(term, n))
getTidyWords <- function(text){
myCorpus <- corpus(text)
metadoc(myCorpus, "language") <- "portuguese"
tokenInfo <- summary(myCorpus)
kwic(myCorpus, "gestor")
myStemMat <- dfm(myCorpus, remove = stopwords("portuguese"), stem = TRUE, remove_punct = TRUE)
mydfm <- dfm(myCorpus, remove = c(stopwords("portuguese"),"scontent.xx.fbcdn.net","https","oh","oe","pra"," v ","como","para","de","do","da","das","dos","isso","esse","nisso","nesse","aquele","nesses","aqueles","aquela","aquelas","que","q","é","sr","governador","rui","costa"), remove_punct = TRUE, remove_numbers= TRUE)
ap_td <- tidy(mydfm)
names(ap_td) <- c("sentimento","term","count")
return(ap_td);
}
words_td <- getTidyWords(text);
p <- words_td %>%
count(sentimento, term, wt = count) %>%
ungroup() %>%
filter(n >= 3) %>%
mutate(term = reorder(term, n)) %>%
ggplot(aes(term, n, fill = sentimento)) +
geom_bar(stat="identity", fill="magenta") +
theme(axis.text.x = element_text(angle = 90, hjust = 1)) +
ylab("Numero de ocorrencias") +
xlab("Palavras") + coord_flip()
print(p);
p <- words_td %>%
count(sentimento, term, wt = count) %>%
ungroup() %>%
filter(n >= 3) %>%
mutate(term = reorder(term, n)) %>%
ggplot(aes(reorder(term, n),n, fill = sentimento)) +
geom_bar(stat="identity", fill="magenta") +
theme(axis.text.x = element_text(angle = 90, hjust = 1)) +
ylab("Numero de ocorrencias") +
xlab("Palavras") + coord_flip()
print(p);
words_td %>%
count(sentimento, term, wt = count) %>%
ungroup() %>%
filter(n >= 3) %>%
mutate(term = reorder(term, n)) %>%
ggplot(aes(reorder(term, n),n, fill = sentimento)) +
geom_bar(stat="identity", fill="magenta")
words_td %>%
count(sentimento, term, wt = count) %>%
ungroup() %>%
filter(n >= 3) %>%
mutate(term = reorder(term, n)) %>%
ggplot(aes(reorder(term, n),n, fill = sentimento)) +
geom_bar(stat="identity", fill="magenta") + coord_flip()
words_td <- words_td %>%
count(sentimento, term, wt = count) %>%
ungroup() %>%
filter(n >= 3)
p <- ggplot(words_td, aes(x = reorder(term, n), y = n, fill = sentimento)) +
geom_bar(stat="identity", fill="magenta") +
theme(axis.text.x = element_text(angle = 90, hjust = 1)) +
ylab("Numero de ocorrencias") +
xlab("Palavras") + coord_flip()
print(p);
words_td <- words_td %>%
count(sentimento, term, wt = count) %>%
ungroup() %>%
filter(n >= 3)
p <- ggplot(words_td, aes(x = reorder(term, n), y = n, fill = sentimento)) +
geom_bar(stat="identity", fill="magenta") +
theme(axis.text.x = element_text(angle = 90, hjust = 1)) +
ylab("Numero de ocorrencias") +
xlab("Palavras") +
geom_text( aes (label = n ) , vjust = - 0.10, hjust = -0.8, size = 2 ) +
coord_flip()
print(p);
?geom_text
words_td
words_td$term
words_td$n
reorder(words_td$terms,words_td$n)
length(words_td$n)
reorder(words_td$terms,words_td$n)
reorder(terms,n)
words_td %>% reorder(terms,n)
words_td <- words_td %>%
count(sentimento, term, wt = count) %>%
ungroup()
words_td <- words_td %>%
count(sentimento, term, wt = count)
words_td <- words_td %>%
count(sentimento, term, wt = count)
words_td <- getTidyWords(text);
words_td <- words_td %>%
count(sentimento, term, wt = count) %>%
ungroup() %>%
filter(n >= 3)
words_td
?reorder
words_td <- getTidyWords(text);
words_td <- words_td %>%
count(sentimento, term, wt = count) %>%
ungroup() %>%
mutate(term = reorder(term,n),decreasing=TRUE)
filter(n >= 3)
words_td <- getTidyWords(text);
words_td <- words_td %>%
count(sentimento, term, wt = count) %>%
ungroup() %>%
mutate(term = reorder(term,n),decreasing=TRUE) %>%
filter(n >= 3)
words_td
words_td <- getTidyWords(text);
words_td <- words_td %>%
count(sentimento, term, wt = count) %>%
ungroup() %>%
mutate(term = reorder(term,n,decreasing=TRUE)) %>%
filter(n >= 3)
words_td
p <- ggplot(words_td, aes(x = reorder(term, n), y = n, fill = sentimento)) +
geom_bar(stat="identity", fill="magenta") +
theme(axis.text.x = element_text(angle = 90, hjust = 1)) +
ylab("Numero de ocorrencias") +
xlab("Palavras") +
geom_text( aes (label = n ) , vjust = - 0.10, hjust = -0.8, size = 2 ) +
coord_flip()
print(p);
getTidyWords <- function(text){
myCorpus <- corpus(text)
metadoc(myCorpus, "language") <- "portuguese"
tokenInfo <- summary(myCorpus)
kwic(myCorpus, "gestor")
myStemMat <- dfm(myCorpus, remove = stopwords("portuguese"), stem = TRUE, remove_punct = TRUE)
mydfm <- dfm(myCorpus, remove = c(stopwords("portuguese"),"scontent.xx.fbcdn.net","https","oh","oe","pra"," v ","como","para","de","do","da","das","dos","isso","esse","nisso","nesse","aquele","nesses","aqueles","aquela","aquelas","que","q","é","sr","governador","rui","costa","senhor"), remove_punct = TRUE, remove_numbers= TRUE)
ap_td <- tidy(mydfm)
names(ap_td) <- c("sentimento","term","count")
return(ap_td);
}
words_td <- getTidyWords(text);
words_td <- words_td %>%
count(sentimento, term, wt = count) %>%
ungroup() %>%
mutate(term = reorder(term,n,decreasing=TRUE)) %>%
filter(n >= 3)
p <- ggplot(words_td, aes(x = reorder(term, n), y = n, fill = sentimento)) +
geom_bar(stat="identity", fill="magenta") +
theme(axis.text.x = element_text(angle = 90, hjust = 1)) +
ylab("Numero de ocorrencias") +
xlab("Palavras") +
geom_text( aes (label = n ) , vjust = - 0.10, hjust = -0.8, size = 2 ) +
coord_flip()
print(p);
words_td <- getTidyWords(text);
words_td <- words_td %>%
count(sentimento, term, wt = count) %>%
ungroup() %>%
mutate(term = reorder(term,n,decreasing=TRUE)) %>%
filter(n >= 3)
p <- ggplot(words_td, aes(x = reorder(term, n), y = n, fill = sentimento)) +
geom_bar(stat="identity", fill="magenta") +
ylab("Numero de ocorrencias") +
xlab("Palavras") +
geom_text( aes (label = n ) , vjust = - 0.10, hjust = -0.8, size = 2 ) +
coord_flip()
print(p);
words_td <- getTidyWords(text);
words_td <- words_td %>%
count(sentimento, term, wt = count) %>%
ungroup() %>%
mutate(term = reorder(term,n,decreasing=TRUE)) %>%
filter(n >= 3)
p <- ggplot(words_td, aes(x = reorder(term, n), y = n, fill = sentimento)) +
geom_bar(stat="identity", fill="magenta") +
ylab("Numero de ocorrencias") +
xlab("") +
geom_text( aes (label = n ) , vjust = - 0.10, hjust = -0.8, size = 2 ) +
coord_flip()
print(p);
words_td <- getTidyWords(text);
words_td <- words_td %>%
count(sentimento, term, wt = count) %>%
ungroup() %>%
mutate(term = reorder(term,n,decreasing=TRUE)) %>%
filter(n >= 3)
p <- ggplot(words_td, aes(x = reorder(term, n), y = n, fill = sentimento)) +
geom_bar(stat="identity", fill="magenta") +
ylab("Numero de ocorrencias") +
xlab("") +
geom_text( aes (label = n ) , vjust = 0, hjust = -0.8, size = 2 ) +
coord_flip()
print(p);
words_td <- getTidyWords(text);
words_td <- words_td %>%
count(sentimento, term, wt = count) %>%
ungroup() %>%
mutate(term = reorder(term,n,decreasing=TRUE)) %>%
filter(n >= 3)
p <- ggplot(words_td, aes(x = reorder(term, n), y = n, fill = sentimento)) +
geom_bar(stat="identity", fill="magenta") +
ylab("Numero de ocorrencias") +
xlab("") +
geom_text( aes (label = n ) , vjust = 0, hjust = 0, size = 2 ) +
coord_flip()
print(p);
top20unig <- read.csv("~/palavrasrui.csv",sep=",")
colnames(top20unig)<-c(Frequency", "UniGram")
colnames(top20unig)<-c("Frequency", "UniGram")
top20unig
p <- ggplot (top20unig, aes(x = reorder(UniGram, Frequency), y= Frequency )) +
geom_bar( stat = "Identity" , fill = "magenta" ) +
geom_text( aes (label = Frequency ) , vjust = - 0.10, hjust = -0.8, size = 2 ) +
xlab( "Termos" ) +
ylab( "Frequência" ) +
theme ( axis.text.x = element_text ( angle = 45 , hjust = 1 ) ) + coord_flip()
print(p)
top20unig
length(top20unig)
length(top20unig[,1])
length(top20unig[,1])-20
(length(top20unig[,1])-20):length(top20unig[,1])
top20unig[(length(top20unig[,1])-20):length(top20unig[,1]),]
top20unig <- top20unig[(length(top20unig[,1])-20):length(top20unig[,1]),]
palavrasfilename <- "palavras_rui_pm.png"
p <- ggplot (top20unig, aes(x = reorder(UniGram, Frequency), y= Frequency )) +
geom_bar( stat = "Identity" , fill = "magenta" ) +
geom_text( aes (label = Frequency ) , vjust = - 0.10, hjust = -0.8, size = 2 ) +
xlab( "Termos" ) +
ylab( "Frequência" ) +
theme ( axis.text.x = element_text ( angle = 45 , hjust = 1 ) ) + coord_flip()
png(palavrasfilename,width=1980,height=1280,res=300)
print(p)
dev.off()
url <- "https://www.facebook.com/ACMNetoOficial/videos/1583197398412041/"
id_pagina <- "366998400031953"
data <- "2017/09/01"
load(paste(workdir,"/fb_oauth",sep=""));
data_inicio <- ymd(as.character(data)) + days(-2);
data_final <- ymd(as.character(data)) + days(2);
mypage <- getPage(id_pagina, token = fb_oauth, feed=TRUE, since= as.character(data_inicio), until=as.character(data_final))
id_post <- mypage$id[which(as.character(mypage$link)%in%url)]
post_dados <- getPost(id_post, token=fb_oauth, n= 10000)
text <- post_dados$comments$message
words_td <- getTidyWords(text);
write(words_td,"~/palavrasneto.csv",sep=",")
words_td
savehistory("~/log.R")
write(words_td,"~/palavrasneto.csv")
write(words_td,file="~/palavrasneto.csv")
words_td <- getTidyWords(text);
write(words_td,file="~/palavrasneto.csv")
words_td
write.csv(words_td,file="~/palavrasneto.csv")
write.csv(words_td,file="~/palavrasneto.csv")
palavrasfilename <- "palavras_neto_bairro.png"
top20unig <- read.csv("~/palavrasneto.csv",sep=",")
top20unig
colnames(top20unig)<-c("Frequency","Unigram")
p <- ggplot (top20unig, aes(x = reorder(UniGram, Frequency), y= Frequency )) +
geom_bar( stat = "Identity" , fill = "magenta" ) +
geom_text( aes (label = Frequency ) , vjust = - 0.10, hjust = -0.8, size = 2 ) +
xlab( "Termos" ) +
ylab( "Frequência" ) +
theme ( axis.text.x = element_text ( angle = 45 , hjust = 1 ) ) + coord_flip()
png(palavrasfilename,width=1980,height=1280,res=300)
print(p)
dev.off()
top20unig
names(top20unig)
top20unig <- top20unig[(length(top20unig[,1])-20):length(top20unig[,1]),]
top20unig
ggplot (top20unig, aes(x = reorder(UniGram, Frequency), y= Frequency )) +
geom_bar( stat = "Identity" , fill = "magenta" ) +
geom_text( aes (label = Frequency ) , vjust = - 0.10, hjust = -0.8, size = 2 ) +
xlab( "Termos" ) +
ylab( "Frequência" ) +
theme ( axis.text.x = element_text ( angle = 45 , hjust = 1 ) ) + coord_flip()
names(top20unig)
ggplot (top20unig, aes(x = reorder(UniGram, Frequency), y= Frequency )) +
geom_bar( stat = "Identity" , fill = "magenta" ) +
geom_text( aes (label = Frequency ) , vjust = - 0.10, hjust = -0.8, size = 2 ) +
xlab( "Termos" ) +
ylab( "Frequência" ) +
theme ( axis.text.x = element_text ( angle = 45 , hjust = 1 ) ) + coord_flip()
ggplot (top20unig, aes(x = reorder(UniGram, Frequency), y= Frequency ))
top20unig$Unigram
ggplot (top20unig, aes(x = reorder(top20unig$UniGram, Frequency), y= Frequency ))
myx <- top20unig$UniGram
myy <- top20unig$Frequency
myy
myx
myx <- as.character(top20unig$UniGram)
myx
top20unig$Unigram
unlist(top20unig$Unigram)
as.character(unlist(top20unig$Unigram))
myx <- as.character(unlist(top20unig$Unigram))
ggplot (aes(x = reorder(myx, myy), y= myy )) +
geom_bar( stat = "Identity" , fill = "magenta" ) +
geom_text( aes (label = myy ) , vjust = - 0.10, hjust = -0.8, size = 2 ) +
xlab( "Termos" ) +
ylab( "Frequência" ) +
theme ( axis.text.x = element_text ( angle = 45 , hjust = 1 ) ) + coord_flip()
top20unig <- read.csv("~/palavrasneto.csv",sep=",")
class(top20unig)
top20unig
names(top20unig)
colnames(top20unig)<-c("Frequency","Unigram")
top20unig
names(top20unig)
colnames(top20unig)<-c("Frequency","UniGram")
ggplot (top20unig, aes(x = reorder(UniGram, Frequency), y= Frequency )) +
geom_bar( stat = "Identity" , fill = "magenta" ) +
geom_text( aes (label = Frequency ) , vjust = - 0.10, hjust = -0.8, size = 2 ) +
xlab( "Termos" ) +
ylab( "Frequência" ) +
theme ( axis.text.x = element_text ( angle = 45 , hjust = 1 ) ) + coord_flip()
top20unig <- top20unig[(length(top20unig[,1])-20):length(top20unig[,1]),]
ggplot (top20unig, aes(x = reorder(UniGram, Frequency), y= Frequency )) +
geom_bar( stat = "Identity" , fill = "magenta" ) +
geom_text( aes (label = Frequency ) , vjust = - 0.10, hjust = -0.8, size = 2 ) +
xlab( "Termos" ) +
ylab( "Frequência" ) +
theme ( axis.text.x = element_text ( angle = 45 , hjust = 1 ) ) + coord_flip()
p <- ggplot (top20unig, aes(x = reorder(UniGram, Frequency), y= Frequency )) +
geom_bar( stat = "Identity" , fill = "magenta" ) +
geom_text( aes (label = Frequency ) , vjust = - 0.10, hjust = -0.8, size = 2 ) +
xlab( "Termos" ) +
ylab( "Frequência" ) +
theme ( axis.text.x = element_text ( angle = 45 , hjust = 1 ) ) + coord_flip()
png(palavrasfilename,width=1980,height=1280,res=300)
print(p)
dev.off()
library(shiny)
library(plotrix)
library(tm)
library(stringr)
library(dplyr)
fa <- function(x) iconv(x, to = "ASCII//TRANSLIT")
getMatrizDeOcorrencias <- function(text){
text <- stringi::stri_trans_tolower(text)
temp <- fa(text)
# Lowercase
# Shrink down to just one white space
temp <- stringr::str_replace_all(temp,"[\\s]+", " ")
temp=str_replace_all(temp,"[^[:graph:]]", " ")
# Split it
any(grepl("I_WAS_NOT_ASCII", iconv(temp, "latin1", "ASCII", sub="I_WAS_NOT_ASCII")))
temp <- stringi::stri_trans_general(temp, "latin-ascii")
temp <- removePunctuation(temp)
temp <- unlist(stringr::str_split(temp, " "))
# Get rid of trailing "" if necessary
indexes <- which(temp == "")
if(length(indexes) > 0){
temp <- temp[-indexes]
}
docs <- Corpus(VectorSource(temp))
docs <- tm_map(docs, removeNumbers)
# Remove english common stopwords
docs <- tm_map(docs, removeWords, stopwords("portuguese"))
# Remove your own stop word
docs <- tm_map(docs, removeWords, c("blabla1", "blabla2","que","ser","pelo","tem","o","lhe","por","pra","de","da","do","essa","esse","isso","aquele","aquilo","desse","disso","daquilo","uma","um","NA"))
#  Remove punctuations
docs <- tm_map(docs, stripWhitespace)
#
dtm <- TermDocumentMatrix(docs)
m <- as.matrix(dtm)
v <- sort(rowSums(m),decreasing=TRUE)
d <- data.frame(word = names(v),freq=v)
return(d)
}
plotPalavras <- function(text, sentimento){
mycol <- switch(sentimento,
geral = "gray50",
negativo = "red",
positivo = "green",
neutro = "blue")
d <- getMatrizDeOcorrencias(text)
nwords <- ifelse(length(as.character(d[,1])) > 10, 10, length(as.character(d[,1])))
d <- d[1:nwords,]
p <- ggplot(d, aes(x = reorder(word, freq), y = freq)) +
geom_bar( stat = "Identity" , fill = mycol) +
geom_text( aes (label = freq ) , vjust = - 0.10, hjust = -0.8, size = 2 ) +
xlab(NULL) +
ylab("Número de Ocorrências") +
coord_flip()
print(p)
}
getIndiceDeSentimento <- function(polaridade){
sentimentos <- toupper(polaridade)
allsentimentos <- c("NEUTRO","NEGATIVO","POSITIVO");
mn <- length(which(sentimentos==allsentimentos[1]));#Neutro
mr <- length(which(sentimentos==allsentimentos[2]));#Negativo
mp <- length(which(sentimentos==allsentimentos[3]));#Positivo
mt <- mr + mn + mp;#Total
indicesentimento <- ifelse(mn == mt, 0, as.numeric((mp-mr)/(mt-mn)))
return(indicesentimento)
}
library(readxl)
file <- read_xlsx("~/comentariosrui1.xlsx")
names(file)
file <- read_xlsx("~/comentariosrui1.xlsx")
allpolaridade <- toupper(file$Polaridade)
isent <- getIndiceDeSentimento(allpolaridade);
isent
plot(-10:10,axes=FALSE,xlab="",ylab="",type="n")
gradient.rect(1,-10,3,10,reds=c(1,0), greens=c(seq(0,1,length=10),seq(1,0,length=10)),blues=c(0,1),gradient="y")
text(x = 3, y=signif(isent,2), labels = paste(intToUtf8(9664),signif(isent,2)),pos = 4)
text(x = 0, y=10,  labels = 1,pos = 4)
text(x = 0, y=-10, labels = -1,pos = 4)
plot(-10:10,axes=FALSE,xlab="",ylab="",type="n")
gradient.rect(1,-10,3,10,reds=c(1,0), greens=c(seq(0,1,length=10),seq(1,0,length=10)),blues=c(0,1),gradient="y")
text(x = 0, y=10,  labels = 1,pos = 4)
text(x = 0, y=-10, labels = -1,pos = 4)
text(x = 3, y=10*signif(isent,2), labels = paste(intToUtf8(9664),signif(isent,2)),pos = 4)
